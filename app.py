import streamlit as st
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import pickle
import os
import random as ran


# ================================
# ì§ˆë¬¸ ëª©ë¡
# ================================
questions_list = [
    "ë‚˜ ì˜¤ëŠ˜ ì§„ì§œ ë„ˆë¬´ ì—´ ë°›ëŠ” ì¼ ìˆì—ˆì–´ã… ã… ",
    "í•™êµê°€ê¸° ì‹«ë‹¤;; ê³ 3 ì–¸ì œ ëë‚˜ëƒã… ã… ",
    "ë‚˜ OOì´ë‘ ì¹œí•´ì§€ê³  ì‹¶ì€ë° ë§ ê±¸ì–´ë³¼ê¹Œ?",
    "ë‚˜ ë°©ê¸ˆ ê¸¸ì—ì„œ ìë¹ ì¡Œë‹¤;;",
    "ìˆ˜ëŠ¥ 200ì¼ ê¹¨ì¡Œë‹¤.... ì–´ë–¡í•˜ëƒ...ã…‹ã…‹",
    "ì˜¤ëŠ˜ ìŒ¤í•œí…Œ ã…ˆã„´ ê¹¨ì¡Œë‹¤...ã…‹ã…‹",
    "ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë• ëƒ?",
    "ì•¼ì•¼ OOì•„ (ë³¸ì¸ì„ ë¶€ë¥´ëŠ” ìƒí™©)"]

questions_extra_list = [
    "ë„ˆì—ê²Œ ë§í• ê²Œ ìˆì–´.. ì‚¬ì‹¤ ë‚´ê°€ ì´ˆëŠ¥ë ¥ì´ ìˆì–´..",
    "í˜¹ì‹œ ë„ˆ.. ì€í•˜ê³„ì—ì„œ ì˜¨ ì™¸ê³„ì¸ì´ì•¼...?",
]

questions = []

# ================================
# ëª¨ë¸ ë° ë¦¬ì†ŒìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
# ================================
@st.cache_resource
def load_resources():
    model = load_model("mal_tu_model.h5")
    with open("tokenizer.pkl", "rb") as f:
        tokenizer = pickle.load(f)
    with open("label_encoder.pkl", "rb") as f:
        label_encoder = pickle.load(f)
    return model, tokenizer, label_encoder

model, tokenizer, label_encoder = load_resources()

# ================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ================================
if "started" not in st.session_state:
    st.session_state.started = False
if "step" not in st.session_state:
    st.session_state.step = 0
if "responses" not in st.session_state:
    st.session_state.responses = []
if "predictions" not in st.session_state:
    st.session_state.predictions = []
if "questions_model" not in st.session_state:
    st.session_state.questions_model = []

# ================================
# íƒ€ì´í‹€ ë° ì†Œê°œ
# ================================
st.markdown("<h1 style='text-align: center;'>ğŸ’¬ ì±„íŒ… ë§íˆ¬ ë¶„ì„ê¸°</h1>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align: center;'>ì•„ë˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”!</h4>", unsafe_allow_html=True)
st.markdown("---")

# ================================
# ì‹œì‘ í™”ë©´ â†’ ë¶„ì„ ì‹œì‘ ë²„íŠ¼
# ================================
if not st.session_state.started:
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘"):
        st.session_state.started = True
        numbers = [0,1,2,3,4,5,6,7]
        number_sample = ran.sample(numbers, 3)
        questions.append(questions_list[int(number_sample[0])])
        questions.append(questions_list[int(number_sample[1])])
        questions.append(questions_list[int(number_sample[2])])
        st.session_state.questions_model.append(questions[0])
        st.session_state.questions_model.append(questions[1])
        st.session_state.questions_model.append(questions[2])
        print(questions)
        st.rerun()
    st.stop()

# ================================
# ì§ˆë¬¸ ë° ì‘ë‹µ íë¦„
# ================================
total_steps = len(st.session_state.questions_model)
step = st.session_state.step
if step < total_steps:
    st.markdown(f"### ì§ˆë¬¸ {step + 1}: {st.session_state.questions_model[step]}")
    user_input = st.text_input("ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”:", key=f"input_{step}")

    if st.button("âœ… ì‘ë‹µ ì™„ë£Œ"):
        if user_input.strip() != "":
            # ì‘ë‹µ ì €ì¥
            st.session_state.responses.append(user_input)

            # ì˜ˆì¸¡
            seq = tokenizer.texts_to_sequences([user_input])
            padded = pad_sequences(seq, maxlen=30, padding='post')
            pred = model.predict(padded)
            st.session_state.predictions.append(pred[0])

            # ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™
            st.session_state.step += 1
            st.rerun()
        else:
            st.warning("ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
else:
    # ================================
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    # ================================
    st.markdown("## ğŸ“Š ë¶„ì„ ê²°ê³¼")
    for idx, question in enumerate(st.session_state.predictions):
        response = st.session_state.responses[idx]
        prediction = st.session_state.predictions[idx]
        label = label_encoder.inverse_transform([np.argmax(prediction)])[0]
        confidence = np.max(prediction) * 100

        st.markdown(f"### {idx + 1}. {st.session_state.questions_model[idx]}")
        st.markdown(f"- âœï¸ ë‹¹ì‹ ì˜ ë‹µ: `{response}`")
        st.markdown(f"- ğŸ” ì˜ˆì¸¡ëœ ë§íˆ¬ ìŠ¤íƒ€ì¼: **{label}** ({confidence:.2f}%)")
        st.progress(int(confidence))
        st.markdown("---")

    # ================================
    # í…ŒìŠ¤íŠ¸ ì¬ì‹œì‘
    # ================================
    if st.button("ğŸ”„ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ê¸°"):
        for key in ["started", "step", "responses", "predictions","questions_model"]:
            del st.session_state[key]
            questions.clear()
        st.rerun()


# questions = ["ì˜¤ëŠ˜ ê¸°ë¶„ ì–´ë•Œ?",
#              "í•™êµì—ì„œ ì„ ìƒë‹˜í•œí…Œ í˜¼ë‚¬ì–´ã… ã…  ìœ„ë¡œí•´ì¤˜ã… ã… ",
#              "ë‚˜ ìƒì¥ ë°›ì•˜ë‹¤! ì¶•í•˜í•´ì¤˜!"]

# # tab1, tab2, tab3 = st.tabs(["ë§íˆ¬ ë¶„ì„ í”„ë¡œê·¸ë¨ğŸ“ˆ", "ì†Œê°œê¸€", "í”„ë¡œê·¸ë¨ ì œì‘ ì½”ë“œ"])

# # ==========================
# # ë°ì´í„° ë° ëª¨ë¸ ì¤€ë¹„
# # ==========================

# @st.cache_resource
# def load_resources():
#     model = load_model("mal_tu_model.h5")
#     with open("tokenizer.pkl", "rb") as f:
#         tokenizer = pickle.load(f)
#     with open("label_encoder.pkl", "rb") as f:
#         label_encoder = pickle.load(f)
#     return model, tokenizer, label_encoder

# model, tokenizer, label_encoder = load_resources()

# # ==========================
# # Streamlit UI
# # ==========================
# if "test_bool" not in st.session_state:
#     st.session_state.test_bool = False

# if st.session_state.test_bool == False:
#     for i in range(2): #ì¤„ë°”ê¿ˆ
#         st.title(" ")
#     st.markdown("<h1 style='text-align: center;'>ğŸ’¬ ì±„íŒ… ë§íˆ¬ ë¶„ì„ê¸°ğŸ”</h1>", unsafe_allow_html=True)
#     st.markdown("<h1 style='text-align: center; font-size: 24px;'>ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì…ë ¥í•˜ì„¸ìš”!</h1>", unsafe_allow_html=True)
#     if st.button("-----------------------------------------------------<í…ŒìŠ¤íŠ¸ ì‹œì‘>---------------------------------------------------------------"):
#         st.session_state.test_bool = True

# if st.session_state.test_bool == True:

#     user_input = st.text_input("ì±„íŒ… ë¬¸ì¥ì„ ì…ë ¥í•´ë³´ì„¸ìš”:")
#     if user_input:
#         seq = tokenizer.texts_to_sequences([user_input])
#         padded = pad_sequences(seq, maxlen=30, padding='post')
#         pred = model.predict(padded)
#         label = label_encoder.inverse_transform([np.argmax(pred)])
#         st.success(f"ì˜ˆì¸¡ëœ ë§íˆ¬ ìŠ¤íƒ€ì¼: **{label[0]}**")